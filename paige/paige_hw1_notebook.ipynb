{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Information\n",
    "\n",
    "Paige Haring\n",
    "\n",
    "peh40@pitt.edu\n",
    "\n",
    "September 1, 2017\n",
    "\n",
    "**Name:** Genesis Corpus\n",
    "\n",
    "**Authors:** N/A\n",
    "\n",
    "**Download URL:** http://www.nltk.org/nltk_data/\n",
    "\n",
    "**Makeup:** This corpus consists of 8 text files of written data, specifically, each file is a translation of the Book of Genesis. The 8 translations include: English- King James Bible, English- World English Bible, Finnish, French, German, lolcat, Portuguese, and Swedish. \n",
    "\n",
    "**License:** Public Domain\n",
    "\n",
    "**Noteworthy:** Of these translations, all represent a spoken human language except for lolcat, which is essentially a meme language \"spoken\" by cats on the internet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-Assessment\n",
    "**Summary:**\n",
    "\n",
    "**Future Wish:** I'd like to learn how to align parallel data automatically to use for translation. That might not even be possible with this corpus despite it all being translations of Genesis, because each text file has a different number of sentences and words. I believe this is because not only are these bibles written by different authors in different languages, but they were also all written in different time periods. I would like to learn more about what makes parallel data \"good\" parallel data in general and if it would be possible to align this or make use of this corpus in some other way to aid in translation. I'd also like to learn what the correct way to handle my encoding problem is. If you have a dataset with a bunch of wacky characters, and utf-8 can't handle it, what is the best way to proceed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8 files in the corpus!\n",
      "english-kjv.txt has 44764 words, 1467 sents\n",
      "english-web.txt has 44054 words, 2232 sents\n",
      "finnish.txt has 32520 words, 2160 sents\n",
      "french.txt has 46116 words, 2004 sents\n",
      "german.txt has 43941 words, 1900 sents\n",
      "lolcat.txt has 17096 words, 821 sents\n",
      "portuguese.txt has 51349 words, 1669 sents\n",
      "swedish.txt has 55950 words, 1386 sents\n",
      "There is a total of 335790 words and 13639 sents in the entire corpus.\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import PlaintextCorpusReader\n",
    "\n",
    "corpus_root = 'data/genesis'\n",
    "\n",
    "#Encoding is latin-1 because utf-8 couldn't read in any of the files besides the two English and the lolcats\n",
    "#I searched around, but I couldn't find what the actual encoding for this corpus is. Latin1 seemed to work the best.\n",
    "gens = PlaintextCorpusReader(corpus_root, r'.*\\.txt', encoding = 'latin-1')\n",
    "\n",
    "print('There are',len(gens.fileids()),'files in the corpus!')\n",
    "\n",
    "for f in gens.fileids():\n",
    "    print(f, 'has', len(gens.words(f)), 'words,', len(gens.sents(f)), 'sents')\n",
    "\n",
    "print('There is a total of', len(gens.words()), 'words and', len(gens.sents()), 'sents in the entire corpus.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genesis Corpus\n",
      "\n",
      "This corpus has been prepared from several web sources; formatting,\n",
      "markup and verse numbers have been stripped.\n",
      "\n",
      "CONTENTS\n",
      "\n",
      "english-kjv.txt - Genesis, King James version (Project Gutenberg)\n",
      "english-web.txt - Genesis, World English Bible (Project Gutenberg)\n",
      "finnish.txt - Genesis, Suomen evankelis-luterilaisen kirkon kirkolliskokouksen vuonna 1992 käyttöön ottama suomennos\n",
      "french.txt - Genesis, Louis Segond 1910\n",
      "german.txt - Genesis, Luther Translation\n",
      "lolcat.txt - Genesis, Lolcat version http://www.lolcatbible.com/\n",
      "portuguese.txt - Genesis, Brazilian Portuguese version - http://www.bibliaonline.com.br\n",
      "swedish.txt - Genesis, Gamla och Nya Testamentet, 1917 (Project Runeberg)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(gens.readme())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "english-kjv.txt: In the beginning God created the heaven and the earth.\n",
      "english-web.txt: In the beginning God created the heavens and the earth.\n",
      "finnish.txt: Alussa Jumala loi taivaan ja maan.\n",
      "french.txt: Au commencement, Dieu créa les cieux et la terre.\n",
      "german.txt: Am Anfang schuf Gott Himmel und Erde.\n",
      "lolcat.txt: Oh hai.\n",
      "portuguese.txt: No princÃ ­ pio, criou Deus os cÃ © us e a terra.\n",
      "swedish.txt: I begynnelsen skapade Gud himmel och jord.\n"
     ]
    }
   ],
   "source": [
    "for f in gens.fileids():\n",
    "    print(f+':',' '.join(gens.sents(f)[0]).replace(' .', '.').replace(' ,', ','))\n",
    "\n",
    "#Note there is an encoding issue with the portuguese text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discovery Question\n",
    "What are the five most frequent words in each text, and how much do these lists differ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "english-kjv.txt : [('unto', 590), ('said', 476), ('thou', 272), ('thy', 267), ('thee', 257)]\n",
      "english-web.txt : [('said', 470), ('father', 270), ('God', 229), ('land', 195), ('Jacob', 185)]\n",
      "finnish.txt : [('sanoi', 324), ('Jumala', 180), ('Jaakob', 138), ('Herra', 123), ('Joosef', 114)]\n",
      "french.txt : [('fils', 317), ('Dieu', 230), ('Jacob', 202), ('père', 199), ('pays', 182)]\n",
      "german.txt : [('szlig', 677), ('sprach', 416), ('Gott', 207), ('h3', 200), ('Jakob', 159)]\n",
      "lolcat.txt : [('teh', 508), ('2', 189), ('wuz', 171), ('Ceiling', 166), ('Cat', 154)]\n",
      "portuguese.txt : [('Ã', 571), ('terra', 349), ('Deus', 240), ('nÃ', 240), ('filhos', 209)]\n",
      "swedish.txt : [('r', 1440), ('f', 1101), ('½', 498), ('sade', 400), ('p', 308)]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "#I want the five most frequent words excluding stopwords, so I'll bring in the stopwords corpus to be able to search for them.\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "for f in gens.fileids():\n",
    "    fd = nltk.FreqDist(gens.words(f))\n",
    "    common = fd.most_common(50)\n",
    "    stops = set(stopwords.words())\n",
    "    common = [(x,y) for (x,y) in common if x.isalnum() and x.lower() not in stops]\n",
    "    print(f, ':', common[:5])\n",
    " \n",
    "#Clearly there are a lot of problems with encoding = latin-1. The characters aren't mapped correctly\n",
    "#Clearly threre are a lot of problems with encoding = latin-1. The characters aren't mapped the the correct symbols."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below is a different attempt to read in the corpus where I'm manually choosing the encoding. This seems like a really silly way to do it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "files = glob.glob('data/genesis/*.txt')\n",
    "files_trimmed = [f[13:] for f in files]\n",
    "\n",
    "raw = []\n",
    "for file in files:\n",
    "    if encoding == 'utf-8':\n",
    "        with open(file, encoding = 'utf-8') as f:\n",
    "            txt = f.read()\n",
    "            raw.append(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['danish',\n",
       " 'dutch',\n",
       " 'english',\n",
       " 'finnish',\n",
       " 'french',\n",
       " 'german',\n",
       " 'hungarian',\n",
       " 'italian',\n",
       " 'kazakh',\n",
       " 'norwegian',\n",
       " 'portuguese',\n",
       " 'russian',\n",
       " 'spanish',\n",
       " 'swedish',\n",
       " 'turkish']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
